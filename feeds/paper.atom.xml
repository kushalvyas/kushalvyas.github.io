<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Kushal Vyas - paper</title><link href="https://kushalvyas.github.io/" rel="alternate"></link><link href="https://kushalvyas.github.io/feeds/paper.atom.xml" rel="self"></link><id>https://kushalvyas.github.io/</id><updated>2024-11-10T00:00:00-06:00</updated><entry><title>Fit pixels, get lables: Meta-learned implciit networks for image segmentation</title><link href="https://kushalvyas.github.io/metaseg.html" rel="alternate"></link><published>2024-11-10T00:00:00-06:00</published><updated>2024-11-10T00:00:00-06:00</updated><author><name>Kushal Vyas</name></author><id>tag:kushalvyas.github.io,2024-11-10:/metaseg.html</id><summary type="html">&lt;p&gt;None&lt;/p&gt;</summary><content type="html">&lt;h2&gt; Page and code coming soon &lt;/h2&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Citation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Coming soon!&lt;/p&gt;</content><category term="paper"></category></entry><entry><title>Learning Transferable Features for Implicit Neural Representations</title><link href="https://kushalvyas.github.io/strainer.html" rel="alternate"></link><published>2024-11-10T00:00:00-06:00</published><updated>2024-11-10T00:00:00-06:00</updated><author><name>Kushal Vyas</name></author><id>tag:kushalvyas.github.io,2024-11-10:/strainer.html</id><summary type="html">&lt;p&gt;None&lt;/p&gt;</summary><content type="html">&lt;!-- | ![img](projects/images/strainer/strainer.png){width="80%"} | 
|:--:| 
| *STRAINER - Learning Transferable Features for Implicit Neural Representations. During training time (a), STRAINER divides an INR into encoder and decoder layers. STRAINER fits similar signals while sharing the encoder layers, capturing a rich set of transferrable features. At test- time, STRAINER serves as powerful initialization for fitting a new signal (b). An INR initialized with STRAINER’s learned encoder features achieves (c) faster convergence and better quality reconstruction compared to baseline SIREN models.* | --&gt;

&lt;figure class="figure text-center"&gt;
  &lt;img src="projects/images/strainer/strainer.png" class="figure-img img-fluid rounded" alt="strainer cover fig"&gt;
  &lt;figcaption class="figure-caption text-center text-justify"&gt;STRAINER - Learning Transferable Features for Implicit Neural Representations. During training time (a), STRAINER divides an INR into encoder and decoder layers. STRAINER fits similar signals while sharing the encoder layers, capturing a rich set of transferrable features. At test- time, STRAINER serves as powerful initialization for fitting a new signal (b). An INR initialized with STRAINER’s learned encoder features achieves (c) faster convergence and better quality reconstruction compared to baseline SIREN models.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;: Implicit neural representations (INRs) have demonstrated success in a variety of applications, including inverse problems and neural rendering. An INR is typically trained to capture one signal of interest, resulting in learned neural features that are highly attuned to that signal. Assumed to be less generalizable, we explore the aspect of transferability of such learned neural features for fitting similar signals. We introduce a new INR training framework, STRAINER that learns transferrable features for fitting INRs to new signals from a given distribution, faster and with better reconstruction quality. Owing to the sequential layer-wise affine operations in an INR, we propose to learn transferable representations by sharing initial encoder layers across multiple INRs with independent decoder layers. At test time, the learned encoder representations are transferred as initialization for an otherwise randomly initialized INR. We find STRAINER to yield extremely powerful initialization for fitting images from the same domain and allow for a ≈ +10dB gain in signal quality early on compared to an untrained INR itself. STRAINER also provides a simple way to encode data-driven priors in INRs. We evaluate STRAINER on multiple in-domain and out-of-domain signal fitting tasks and inverse problems and further provide detailed analysis and discussion on the transferability of STRAINER’s features.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h4&gt;Image Fitting (In domain and Out of Domain)&lt;/h4&gt;

&lt;figure class="figure text-center"&gt;
  &lt;img src="projects/images/strainer/psnr_quality_strainer.png" class="figure-img img-fluid rounded" alt="strainer pspnr fig" width="60%"&gt;
  &lt;figcaption class="figure-caption text-center text-justify"&gt;STRAINER captures a highly transferable representation from just 10 images and 24 seconds of training time! Refer to Table 3,5 in the paper for baseline evaluation for in-domain image fitting and training complexity. STRAINER  features are also powerful initialization for out-of-domain image fitting indicating that STRAINER captures features highly generalizable to other natural images (Table 2,3).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h4&gt;STRAINER Learns High Frequency Faster&lt;/h4&gt;

&lt;!-- | ![img](projects/images/strainer/pca_cat_plot_v4.png) | 
|:--:| 
| *We visualize (a) the first principal component of the learned encoder features for STRAINER and corresponding layer for SIREN . At iteration 0, STRAINER’s feature already capture a low dimensional structure allowing it to quickly adapt to the cat image. High frequency detail emerges in STRAINER’s learned features by iteration 50, whereas SIREN is lacking at iteration 100. The inset showing the power spectrum of the reconstructed image further confirms that STRAINER learns high frequency faster. We also show the (b) reconstructed images and remark that STRAINER fits high frequencies faster.* | --&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;figure class="figure text-center"&gt;
  &lt;img src="projects/images/strainer/pca_cat_plot_v4.png" class="figure-img img-fluid rounded" alt="strainer cat fig" width=80%&gt;
  &lt;figcaption class="figure-caption text-center text-justify"&gt;We visualize (a) the first principal component of the learned encoder features for STRAINER and corresponding layer for SIREN . At iteration 0, STRAINER’s feature already capture a low dimensional structure allowing it to quickly adapt to the cat image. High frequency detail emerges in STRAINER’s learned features by iteration 50, whereas SIREN is lacking at iteration 100. The inset showing the power spectrum of the reconstructed image further confirms that STRAINER learns high frequency faster. We also show the (b) reconstructed images and remark that STRAINER fits high frequencies faster.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h4&gt;Visualizing Density of Partitions in Input Space of Learned Models&lt;/h4&gt;

&lt;!-- | ![img](projects/images/strainer/partitions_v7_arxiv.png) | 
|:--:| 
| *We use the method introduced in [20] to approximate the input space partition of the INR. We present the input space partitions for layers 2,3,4 across (a) Meta-learned 5K and STRAINER initialization and (b) at test time optimization. STRAINER learns an input space partitioning which is more attuned to the prior of the dataset, compared to meta learned which is comparatively more random. We also observe that SIREN (iii) learns an input space partitioning highly specific to the image leading to inefficient transferability for fitting a new image (iv) with significantly different underlying partitioned input space This explains the better in-domain performance of STRAINER compared to Meta-learned 5K , as the shallower layers after pre-training provide a better input space subdivision to the deeper layers to further subdivide.* | --&gt;

&lt;figure class="figure text-center"&gt;
  &lt;img src="projects/images/strainer/partitions_v7_arxiv.png" class="figure-img img-fluid rounded" alt="strainer partition fig" width=80%&gt;
  &lt;figcaption class="figure-caption text-center text-justify"&gt;We use the method introduced in [20] to approximate the input space partition of the INR. We present the input space partitions for layers 2,3,4 across (a) Meta-learned 5K and STRAINER initialization and (b) at test time optimization. STRAINER learns an input space partitioning which is more attuned to the prior of the dataset, compared to meta learned which is comparatively more random. We also observe that SIREN (iii) learns an input space partitioning highly specific to the image leading to inefficient transferability for fitting a new image (iv) with significantly different underlying partitioned input space This explains the better in-domain performance of STRAINER compared to Meta-learned 5K , as the shallower layers after pre-training provide a better input space subdivision to the deeper layers to further subdivide.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For more details, please refer &lt;a href="https://arxiv.org/abs/2409.09566"&gt;full paper&lt;/a&gt;!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Citation&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="err"&gt;@&lt;/span&gt;&lt;span class="nx"&gt;misc&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nx"&gt;vyas2024learningtransferablefeaturesimplicit&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;title&lt;/span&gt;&lt;span class="p"&gt;={&lt;/span&gt;&lt;span class="nx"&gt;Learning&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Transferable&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Features&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Implicit&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Neural&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Representations&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;author&lt;/span&gt;&lt;span class="p"&gt;={&lt;/span&gt;&lt;span class="nx"&gt;Kushal&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Vyas&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Ahmed&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Imtiaz&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Humayun&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Aniket&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Dashpute&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Richard&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;G&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Baraniuk&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Ashok&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Veeraraghavan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Guha&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nx"&gt;Balakrishnan&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;year&lt;/span&gt;&lt;span class="p"&gt;={&lt;/span&gt;&lt;span class="mi"&gt;2024&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;eprint&lt;/span&gt;&lt;span class="p"&gt;={&lt;/span&gt;&lt;span class="m m-Double"&gt;2409.09566&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;archivePrefix&lt;/span&gt;&lt;span class="p"&gt;={&lt;/span&gt;&lt;span class="nx"&gt;arXiv&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;primaryClass&lt;/span&gt;&lt;span class="p"&gt;={&lt;/span&gt;&lt;span class="nx"&gt;cs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;CV&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nx"&gt;url&lt;/span&gt;&lt;span class="p"&gt;={&lt;/span&gt;&lt;span class="nx"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="c1"&gt;//arxiv.org/abs/2409.09566},&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="paper"></category></entry></feed>