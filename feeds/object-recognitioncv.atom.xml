<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Kushal Vyas - Object Recognition,CV</title><link href="https://kushalvyas.github.io/" rel="alternate"></link><link href="https://kushalvyas.github.io/feeds/object-recognitioncv.atom.xml" rel="self"></link><id>https://kushalvyas.github.io/</id><updated>2016-07-13T00:00:00-05:00</updated><entry><title>Simple Object Recognition techniques</title><link href="https://kushalvyas.github.io/Obj_CV.html" rel="alternate"></link><published>2016-07-13T00:00:00-05:00</published><updated>2016-07-13T00:00:00-05:00</updated><author><name>Kushal Vyas</name></author><id>tag:kushalvyas.github.io,2016-07-13:/Obj_CV.html</id><summary type="html">&lt;p&gt;A brief introduction on object recognition techniques in  CV&lt;/p&gt;</summary><content type="html">&lt;p&gt;Object recognition is one of the hot topics in computer vision. Particularly, of much significance, it has various applications in robotics, identification, interpretation and such image oriented tasks. &lt;/p&gt;
&lt;p&gt;One can ramify between Object recognition into 4 major subsets such as :&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Template based approach&lt;/strong&gt; : We take the object and match the object with distribution pattern of intensities. It&amp;rsquo;s quite exhaustive is not invariant to geometric transformations inside search image
    Eg: Template Matching . However, this isint much sturdy.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Geometric approach&lt;/strong&gt; : Recognize the object on basis of edges, corners, angles. Then we create a one 2  one match and then make a transformation that handles rotation, scaling, etx.&lt;br /&gt;
    Eg: Matching w.r.t positioning of objects. Classifying patterns&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Graph based approach&lt;/strong&gt; : we match similar types of structures. Encode the relationship between structures rather than the geometry of the figure.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bag of Visual Words&lt;/strong&gt; : I will cover Bag of Words in a seperate post &lt;a href="https://kushalvyas.github.io/BOV.html"&gt;Bag of Words&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;I&amp;rsquo;ll be going through a couple of common techniques. Firstly I&amp;rsquo;ll introduce template matching and in the follow, using probabilistic recognition , then moving on to Machine learning applications such as using BOW models coupled with SVM , or feature extrapolation and recognition using neural nets.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Template based aproach&lt;/strong&gt; 
Well, there are  a few contentions i;d like to make when we use this approach. Shape based approach is not the key or the best method for recognition. But , in industry, all methods have their perks. Say we have an industry converyor belt that is suppossed to carry only boxes or T- Joints or anything so simply extrapolable and uniform that it is feasible to use shape matching rather than going for complex approaches like using nets, or using SVM along with bag of words. Then I&amp;rsquo;d say, template matching or shape based matching is the best bet in terms of accuracy as well as speed. &lt;/p&gt;
&lt;p&gt;Lets dive a little deeper in the aforementioned topic.
I&amp;rsquo;ll be using template matching as an example to explain how Shape based matching works. Consider two images. The template image (T) and the actual image (I). We say that we want to find the location / occurence of template inside the actual image.&lt;/p&gt;
&lt;p&gt;In simple words I can say, return True, iff &lt;span class="math"&gt;\(T \subseteq I\)&lt;/span&gt;. But life aint so simple. In reality, every pixel needs to be iterated over and checked. It can be said that the a template is belonging to a particular image iff, all pixels match exactly. i.e. the sum of ( Absolute Difference between every pixel must be zero).&lt;/p&gt;
&lt;div class="math"&gt;$$SAD(x, y) = \sum_{i=0}^{T_{\text{rows}}}\sum_{j=0}^{T_{\text{cols}}} {\text{Diff}(x+i, y+j,i,j)}$$&lt;/div&gt;
&lt;p&gt;Here&amp;rsquo;s how the above formula works.&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(SAD\)&lt;/span&gt; : sum of absolute differences.
&lt;span class="math"&gt;\(SAD (x, y)\)&lt;/span&gt; : the SAD of a particular pixel location in the actual Image &lt;span class="math"&gt;\(I\)&lt;/span&gt; &lt;/p&gt;
&lt;p&gt;Each pixel in &lt;span class="math"&gt;\(I\)&lt;/span&gt; can be represented using &lt;span class="math"&gt;\((x, y)\)&lt;/span&gt;. It has an intensity, or color value expresed as &lt;span class="math"&gt;\(Intensity(I(x,y))\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now, a pixel in template image &lt;span class="math"&gt;\(T(p,q)\)&lt;/span&gt; will have intensity as &lt;span class="math"&gt;\(Intensity(T(p,q))\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A search window is created that is of the size of template image. The window is then slid over the actual Image I and every time SAD is computed. For checking single occurence of template the iterations can be stopped once SAD is &lt;span class="math"&gt;\(0\)&lt;/span&gt;, or else it can be continued until the end of &lt;span class="math"&gt;\(I\)&lt;/span&gt; is reached. &lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll be implementing the algorithm using opencv , python &lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/c151fd726bb3d439b721b264f3d50843.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;"""
Template matching using opencv

Run : python file.py &lt;templateImage&gt; &lt;actualImage&gt;


"""

import sys, cv2
import numpy as np

def main(template, actualImage):
	tImage = cv2.imread(template, 0)
	aImage = cv2.imread(actualImage)
	aCopy = aImage.copy()
	aImage = cv2.cvtColor(aImage, cv2.COLOR_BGR2GRAY)
	th, tw = tImage.shape[:2]

	match = cv2.matchTemplate(aImage, tImage, cv2.TM_SQDIFF)
	minmaxlocs = cv2.minMaxLoc(match)
	topcorner = minmaxlocs[-2]
	bottomcorner=  (topcorner[0] + tw, topcorner[1]+th)
	cv2.rectangle(aCopy, topcorner, bottomcorner, (0, 0, 255), 2)

	cv2.imshow("actual Iamge", aCopy)
	cv2.waitKey()


if __name__ == '__main__':
	args = sys.argv[1:]
	print args
	if (len(args) is not 2):
		print "Please pass cmd args for template and actual image"
		sys.exit(-1)

	main(args[0], args[1])&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;Take a look at &lt;span class="math"&gt;\(line 14\)&lt;/span&gt;, it states &lt;code&gt;cv2.TM_SQDIFF&lt;/code&gt; parameter in matchTemplate(). Opencv&amp;rsquo;s rendition for SAD can be delineated as : 
&lt;/p&gt;
&lt;div class="math"&gt;$$R(x, y) = \sum_{i, j}\ {(\text{T}(i,j) - \text{I}(x+i, y+j))^2}$$&lt;/div&gt;
&lt;p&gt;And here is the output ! We will search a pair of glares from this paraphenalia
&lt;center&gt;
&lt;img alt="crop" src="https://kushalvyas.github.io/images/tempCrop.jpg" /&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt="original" src="https://kushalvyas.github.io/images/optemplate.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;Okay, so template matching can be established using the opencv api. Its&amp;rsquo; quite simple to implement in plain ol c++ as well. Not a biggie.  We&amp;rsquo;ll use the helper functions for image reading , accessing pixel value, etc. but the rest can be quite easily implemented using a bunch of &lt;code&gt;for loops&lt;/code&gt;&lt;/p&gt;
&lt;div class="gist"&gt;
    &lt;script src='https://gist.github.com/0667c6a249f3397ee7de1db0cf04555d.js'&gt;&lt;/script&gt;
    &lt;noscript&gt;
        &lt;pre&gt;&lt;code&gt;/*
Author : Kushal Vyas
Code for template matching as implemented by opencv.

*/
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/opencv.hpp"
#include "iostream"
#include "cmath"

using namespace std;
using namespace cv;

int main(){
	cout&lt;&lt;"Template matching \n";
	Mat tImage, aImage, aCopy;
	tImage = imread("tempCrop.jpg",0);
	aImage = imread("temA1.jpg",0);
	aCopy = imread("temA1.jpg");


	// performing template matching using SAD method
	Size Tsize, Isize ;
	Tsize = tImage.size();
	Isize = aImage.size();

	
	long int minSAD = 999999999999, SAD=0;
	int xloc=0, yloc=0, sadloc=0;
	// loop through the actual image
	int a_i, a_j;
	for (a_i =0; a_i &lt; Isize.height - Tsize.height; a_i++){
		for (a_j=0; a_j &lt; Isize.width - Tsize.width; a_j++){
			SAD = 0;

			// check every pixel of actual image with the template image
			// loop through the template image
			for(int t_j=0; t_j &lt; Tsize.width; t_j++){
				for(int t_i=0; t_i &lt; Tsize.height; t_i++){
					uchar aT = aImage.at&lt;uchar&gt;( a_i+t_i, a_j+t_j );
					uchar tT = tImage.at&lt;uchar&gt;(t_i, t_j);
					SAD += pow(abs(int(aT) - int(tT)),2);
				}
			}
			// cout &lt;&lt;"SASD sis "&lt;&lt;SAD&lt;&lt;endl; 
			// save the best found position
			if(minSAD &gt; SAD ){
				cout &lt;&lt;" SAD "&lt;&lt; SAD&lt;&lt;endl;
				minSAD = SAD;
				yloc = a_i;
				xloc = a_j;
				sadloc = SAD;
			}
		}
	}

	cout&lt;&lt;"Template size"&lt;&lt;Tsize&lt;&lt;endl;
	cout&lt;&lt;"Image size"&lt;&lt;Isize&lt;&lt;endl;

	cout&lt;&lt;a_i&lt;&lt;" "&lt;&lt;a_j&lt;&lt;endl;

	cout&lt;&lt;xloc&lt;&lt;","&lt;&lt;yloc&lt;&lt;" SAD is "&lt;&lt;sadloc&lt;&lt;endl;

	// create a rectangle to demarkate the region
	rectangle(aCopy, Point(xloc, yloc), Point(xloc+Tsize.width, yloc+Tsize.height), Scalar(0,0,255), 2);

	// imshow("Template image", tImage);
	imshow("Actual image", aImage);
	imshow("Matched Image", aCopy);
	waitKey();
	destroyAllWindows();

	return 0;
}&lt;/code&gt;&lt;/pre&gt;
    &lt;/noscript&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;You can find my remaining code on &lt;a href="https://github.com/kushalvyas/ObjectDetectionPython"&gt;Github&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;__ remaining posts on other approaches coming soon &amp;hellip; __&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Object Recognition,CV"></category><category term="ObjectRecognition"></category><category term="CV"></category></entry></feed>